{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b5173-0484-4c25-b850-aaad00823b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3ab8b65-da0c-4845-b4f9-44c321284f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/ext3/miniconda3/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gdown\n",
    "import json\n",
    "from minicons import scorer\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec9737b3-0415-4c51-84f1-bf6dede5d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ddb80f0-c1ee-4292-945e-ab11e4f743b2",
   "metadata": {},
   "source": [
    "### Load First Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6b78ff2-b632-4935-8cae-71cdcba79adb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence_good</th>\n",
       "      <th>sentence_bad</th>\n",
       "      <th>one_prefix_prefix</th>\n",
       "      <th>one_prefix_word_good</th>\n",
       "      <th>one_prefix_word_bad</th>\n",
       "      <th>dependency_length</th>\n",
       "      <th>field</th>\n",
       "      <th>linguistics_term</th>\n",
       "      <th>UID</th>\n",
       "      <th>simple_LM_method</th>\n",
       "      <th>one_prefix_method</th>\n",
       "      <th>two_prefix_method</th>\n",
       "      <th>lexically_identical</th>\n",
       "      <th>pairID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A niece of most senators hasn't descended most slopes.</td>\n",
       "      <td>A niece of most senators haven't descended most slopes.</td>\n",
       "      <td>A niece of most senators</td>\n",
       "      <td>hasn't</td>\n",
       "      <td>haven't</td>\n",
       "      <td>5</td>\n",
       "      <td>morphology</td>\n",
       "      <td>subject_verb_agreement</td>\n",
       "      <td>distractor_agreement_relational_noun</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The sketch of those trucks hasn't hurt Alan.</td>\n",
       "      <td>The sketch of those trucks haven't hurt Alan.</td>\n",
       "      <td>The sketch of those trucks</td>\n",
       "      <td>hasn't</td>\n",
       "      <td>haven't</td>\n",
       "      <td>5</td>\n",
       "      <td>morphology</td>\n",
       "      <td>subject_verb_agreement</td>\n",
       "      <td>distractor_agreement_relational_noun</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A newspaper article about the Borgias has disagreed with Marcus.</td>\n",
       "      <td>A newspaper article about the Borgias have disagreed with Marcus.</td>\n",
       "      <td>A newspaper article about the Borgias</td>\n",
       "      <td>has</td>\n",
       "      <td>have</td>\n",
       "      <td>6</td>\n",
       "      <td>morphology</td>\n",
       "      <td>subject_verb_agreement</td>\n",
       "      <td>distractor_agreement_relational_noun</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The niece of most guests has cleaned every college campus.</td>\n",
       "      <td>The niece of most guests have cleaned every college campus.</td>\n",
       "      <td>The niece of most guests</td>\n",
       "      <td>has</td>\n",
       "      <td>have</td>\n",
       "      <td>5</td>\n",
       "      <td>morphology</td>\n",
       "      <td>subject_verb_agreement</td>\n",
       "      <td>distractor_agreement_relational_noun</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A sketch of lights doesn't appear.</td>\n",
       "      <td>A sketch of lights don't appear.</td>\n",
       "      <td>A sketch of lights</td>\n",
       "      <td>doesn't</td>\n",
       "      <td>don't</td>\n",
       "      <td>4</td>\n",
       "      <td>morphology</td>\n",
       "      <td>subject_verb_agreement</td>\n",
       "      <td>distractor_agreement_relational_noun</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      sentence_good  \\\n",
       "0            A niece of most senators hasn't descended most slopes.   \n",
       "1                      The sketch of those trucks hasn't hurt Alan.   \n",
       "2  A newspaper article about the Borgias has disagreed with Marcus.   \n",
       "3        The niece of most guests has cleaned every college campus.   \n",
       "4                                A sketch of lights doesn't appear.   \n",
       "\n",
       "                                                        sentence_bad  \\\n",
       "0            A niece of most senators haven't descended most slopes.   \n",
       "1                      The sketch of those trucks haven't hurt Alan.   \n",
       "2  A newspaper article about the Borgias have disagreed with Marcus.   \n",
       "3        The niece of most guests have cleaned every college campus.   \n",
       "4                                   A sketch of lights don't appear.   \n",
       "\n",
       "                       one_prefix_prefix one_prefix_word_good  \\\n",
       "0               A niece of most senators               hasn't   \n",
       "1             The sketch of those trucks               hasn't   \n",
       "2  A newspaper article about the Borgias                  has   \n",
       "3               The niece of most guests                  has   \n",
       "4                     A sketch of lights              doesn't   \n",
       "\n",
       "  one_prefix_word_bad  dependency_length       field        linguistics_term  \\\n",
       "0             haven't                  5  morphology  subject_verb_agreement   \n",
       "1             haven't                  5  morphology  subject_verb_agreement   \n",
       "2                have                  6  morphology  subject_verb_agreement   \n",
       "3                have                  5  morphology  subject_verb_agreement   \n",
       "4               don't                  4  morphology  subject_verb_agreement   \n",
       "\n",
       "                                    UID  simple_LM_method  one_prefix_method  \\\n",
       "0  distractor_agreement_relational_noun              True               True   \n",
       "1  distractor_agreement_relational_noun              True               True   \n",
       "2  distractor_agreement_relational_noun              True               True   \n",
       "3  distractor_agreement_relational_noun              True               True   \n",
       "4  distractor_agreement_relational_noun              True               True   \n",
       "\n",
       "   two_prefix_method  lexically_identical pairID  \n",
       "0              False                False      0  \n",
       "1              False                False      1  \n",
       "2              False                False      2  \n",
       "3              False                False      3  \n",
       "4              False                False      4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def load_jsonl(file_path):\n",
    "    \"\"\"Load a JSONL file into a DataFrame.\"\"\"\n",
    "    data = []\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        for line in file:\n",
    "            data.append(json.loads(line))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Specify the path to your dataset\n",
    "dataset_path = \"/scratch/qm351/nlu_final_data/distractor_agreement_relational_noun.jsonl\"\n",
    "\n",
    "# Load the dataset\n",
    "df_dgrn = load_jsonl(dataset_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame to inspect the data\n",
    "pd.set_option('display.max_colwidth', None) \n",
    "df_dgrn.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0bafc8-972c-4921-8e98-54b81cd8862c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['sentence_good', 'sentence_bad', 'one_prefix_prefix',\n",
       "       'one_prefix_word_good', 'one_prefix_word_bad', 'dependency_length',\n",
       "       'field', 'linguistics_term', 'UID', 'simple_LM_method',\n",
       "       'one_prefix_method', 'two_prefix_method', 'lexically_identical',\n",
       "       'pairID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dgrn.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c8841c-1955-4971-a550-8fa61b9cde3c",
   "metadata": {},
   "source": [
    "### Priming and Token Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fd54a7e1-3c04-4f79-9ca4-e53e35d2f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [02:37,  6.34it/s]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the evaluation function\n",
    "def evaluate_priming_effect(model, tokenizer, row, num_labels, device):\n",
    "    model.eval()\n",
    "    classifier = nn.Linear(model.config.hidden_size, num_labels).to(device)\n",
    "    results = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # Extract sentences and tokens from the row\n",
    "        primer_sentences = [row['sentence_good'], row['sentence_bad']]\n",
    "        target_tokens = [row['one_prefix_word_good'], row['one_prefix_word_bad']]\n",
    "        \n",
    "        for primer in primer_sentences:\n",
    "            encoded_input = tokenizer(primer, return_tensors='pt').to(device)\n",
    "            outputs = model(**encoded_input)\n",
    "            logits = classifier(outputs.last_hidden_state)\n",
    "            logits_at_last_position = logits[0, -1, :]  # Get logits at the last position for all possible tokens\n",
    "            probs_at_last_position = F.softmax(logits_at_last_position, dim=0)\n",
    "\n",
    "            predictions = {}\n",
    "            for token in target_tokens:\n",
    "                token_ids = tokenizer.encode(token, add_special_tokens=False)\n",
    "                token_probs = probs_at_last_position[token_ids]\n",
    "                token_max_prob = token_probs.max().item() if token_probs.numel() > 1 else token_probs.item()\n",
    "                predictions[token] = token_max_prob\n",
    "\n",
    "            results[primer] = predictions\n",
    "\n",
    "    return results\n",
    "\n",
    "# Check for GPU availability\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased').to(device)\n",
    "num_labels = tokenizer.vocab_size\n",
    "\n",
    "# Process each row and evaluate priming effect\n",
    "all_results = []\n",
    "for index, row in tqdm(df_dgrn.iterrows()):\n",
    "    result = evaluate_priming_effect(model, tokenizer, row, num_labels, device)\n",
    "    all_results.append(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3206b566-b723-4b58-a6fd-039c141aaa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"prime_results.json\"\n",
    "\n",
    "# Prepare to write to the file\n",
    "with open(file_path, 'w') as file:\n",
    "    json.dump(all_results, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751d02dd-92dc-4021-afde-93c332a47721",
   "metadata": {},
   "source": [
    "### Text Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b6c355c-e5d0-41bb-950e-e89bcc6190fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "173it [00:27,  6.31it/s]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "class BertForTextGeneration(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BertForTextGeneration, self).__init__()\n",
    "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "        self.decoder = nn.Linear(768, 10000)  # Match this with the tokenizer's vocabulary size if different\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, input_ids):\n",
    "        embeddings = self.bert(input_ids).last_hidden_state\n",
    "        logits = self.decoder(embeddings[:, -1, :])  # Use the last token's embedding for prediction\n",
    "        return self.softmax(logits)\n",
    "\n",
    "# Load the dataset\n",
    "def load_dataset(path):\n",
    "    return pd.read_json(path, lines=True)\n",
    "\n",
    "def run_text_gen(dataset_path):\n",
    "    df = load_dataset(dataset_path)\n",
    "\n",
    "    # Prepare tokenizer and model\n",
    "    tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "    model = BertForTextGeneration().to('cuda')  # Use GPU if available\n",
    "\n",
    "    # Prepare batches of sentences\n",
    "    batch_size = 5  # You can adjust batch size based on your GPU memory\n",
    "    sentences = df['sentence_good'].tolist()  # Assuming you want to process 'sentence_good'\n",
    "    predicted_words = []\n",
    "\n",
    "    # Process sentences in batches\n",
    "    for i in tqdm(range(0, len(sentences), batch_size)):\n",
    "        batch_sentences = sentences[i:i+batch_size]\n",
    "        inputs = tokenizer(batch_sentences, padding=True, return_tensors='pt', truncation=True).to('cuda')\n",
    "\n",
    "        with torch.no_grad():\n",
    "            predictions = model(inputs['input_ids'])\n",
    "            next_word_logits = predictions  # Contains logits for each sentence in the batch\n",
    "            predicted_word_ids = torch.argmax(next_word_logits, dim=1)\n",
    "            # Decode each token and handle unused tokens and subword fragments\n",
    "            predicted_batch_words = []\n",
    "            for pid in predicted_word_ids.cpu().numpy():\n",
    "                decoded_word = tokenizer.decode([pid])\n",
    "                if '[unused' in decoded_word:\n",
    "                    decoded_word = '[unknown]'  # Replace unused tokens with '[unknown]'\n",
    "                elif '##' in decoded_word:\n",
    "                    decoded_word = decoded_word.replace('##', '')  # Attempt to clean subword fragments\n",
    "                predicted_batch_words.append(decoded_word)\n",
    "            predicted_words.extend(predicted_batch_words)\n",
    "\n",
    "    df['predicted_words'] = predicted_words\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d04c83e9-4140-4d52-aa5b-e6a34105e0f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 123.82it/s]\n"
     ]
    }
   ],
   "source": [
    "animate_subject_passive_path = '/scratch/qm351/nlu_final_data/animate_subject_passive.jsonl'\n",
    "bert_animate_subject_passive = run_text_gen(animate_subject_passive_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "99f49ef2-580c-4385-b79f-bdb0a9981d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert_animate_subject_passive['predicted_words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e88e34c1-1082-4d72-870d-4c278afb3396",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 122.27it/s]\n"
     ]
    }
   ],
   "source": [
    "distractor_agreement_relational_noun_path = '/scratch/qm351/nlu_final_data/distractor_agreement_relational_noun.jsonl'\n",
    "bert_distractor_agreement_relational_noun = run_text_gen(distractor_agreement_relational_noun_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "230a19d2-47b2-4cb9-8299-404d50ccaa9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_animate_subject_passive.to_csv('bert_animate_subject_passive_predicted.csv')\n",
    "bert_distractor_agreement_relational_noun.to_csv('bert_distractor_agreement_relational_noun_predicted.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c70a192-f07b-48d9-a53b-292324db7c26",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flash_attn_env",
   "language": "python",
   "name": "flash_attn_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
